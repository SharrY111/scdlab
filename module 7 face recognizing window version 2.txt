import cv2
from tkinter import *
from PIL import Image, ImageTk
import mysql.connector


class FaceRecognizing:
    def __init__(self, root):
        self.root = root
        self.root.geometry("1460x1000")
        self.root.title("Face Recognition")
        self.root.resizable(False, False)

        # Header image
        header_img = Image.open(r"C:\Users\Win 10\Desktop\facccc\images\1.png")
        header_img = header_img.resize((1460, 100))
        self.header_photo = ImageTk.PhotoImage(header_img)
        header_label = Label(self.root, image=self.header_photo)
        header_label.place(x=0, y=0, width=1460, height=100)

        # Background image
        background_img = Image.open(r"C:\Users\Win 10\Desktop\facccc\images\2.png")
        background_img = background_img.resize((1460, 900))
        self.background_photo = ImageTk.PhotoImage(background_img)
        background_label = Label(self.root, image=self.background_photo)
        background_label.place(x=0, y=100, width=1460, height=900)

        # First image
        img_top = Image.open(r"C:\Users\Win 10\Desktop\facccc\images\12.jpg")
        img_top = img_top.resize((630, 650))
        self.photoimg_top = ImageTk.PhotoImage(img_top)

        # Text label
        title_lbl = Label(self.root, text="FACE RECOGNITION", font=("times new roman", 30, "bold"), bg="white",
                          fg="red")
        title_lbl.place(x=0, y=100, width=1460, height=45)

        # Second image
        img_bottom = Image.open(r"C:\Users\Win 10\Desktop\facccc\images\11.jpg")
        img_bottom = img_bottom.resize((1400, 1200))
        self.photoimg_bottom = ImageTk.PhotoImage(img_bottom)

        f_lbl = Label(self.root, image=self.photoimg_bottom)
        f_lbl.place(x=0, y=150, width=1466, height=950)

        # Button
        b1_1 = Button(f_lbl, text="Face Recognition", command=self.face_recog, cursor="hand2", font=("", 18, "bold"),
                      bg="red", fg="white")
        b1_1.place(x=1000, y=650, width=300, height=100)

    def face_recog(self):
        def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, text, clf):
            # Convert the image to grayscale
            gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

            # Detect faces in the grayscale image
            features = classifier.detectMultiScale(gray_image, scaleFactor, minNeighbors)

            coord = []
            for (x, y, w, h) in features:
                # Draw a green rectangle around the detected face
                cv2.rectangle(img, (x, y), (x + w + 20, y + h + 20), (0, 255, 0), 3)

                # Predict the ID and confidence of the detected face
                std_id, predict = clf.predict(gray_image[y:y + h + 20, x:x + w + 20])
                confidence = int((100 * (1 - predict / 300)))

                # Connect to the MySQL database
                conn = mysql.connector.connect(host="localhost", user="root", password="pass11",
                                               database="face_recognization", auth_plugin='mysql_native_password')
                my_cursor = conn.cursor()

                # Retrieve student information
                my_cursor.execute("select Name from srudent where std_id=" + str(std_id))
                n = my_cursor.fetchone()
                n = str(n)
                n = "".join(n)

                my_cursor.execute("select Roll_no from srudent where std_id=" + str(std_id))
                r = my_cursor.fetchone()
                r = str(r)
                r = "".join(r)

                my_cursor.execute("select Department from srudent where std_id=" + str(std_id))
                d = my_cursor.fetchone()
                d = str(d)
                d = "".join(d)

                my_cursor.execute("select std_id from srudent where std_id=" + str(std_id))
                i = my_cursor.fetchone()
                i = str(i)
                i = "".join(i)

                # New code for accuracy calculation
                result = clf.predict(gray_image[y:y + h + 20, x:x + w + 20])

                if predict < 500:
                    if result[1] < 500:
                        confidence = int(100 * (1 - (result[1]) / 300))
                        display_string = str(confidence) + '% confidence it is the user'
                        cv2.putText(img, display_string, (250, 250), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 3)
                        cv2.putText(img, f"Accuracy: {confidence}%", (x, y - 100), cv2.FONT_HERSHEY_COMPLEX, 0.8,
                                    (0, 255, 0), 3)

                if confidence > 80:
                    cv2.putText(img, f"std_id: {i}", (x, y - 75), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 255, 255), 3)
                    cv2.putText(img, f"Roll_no: {r}", (x, y - 55), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 255, 255), 3)
                    cv2.putText(img, f"Name: {n}", (x, y - 30), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 255, 255), 3)
                    cv2.putText(img, f"Department: {d}", (x, y - 5), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 255, 255), 3)

                else:
                    cv2.rectangle(img, (x, y), (x + w + 20, y + h + 20), (0, 0, 255), 3)
                    cv2.putText(img, "Unknown Face", (x, y - 5), cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 255, 255), 3)

                coord = [x, y, w, h]

            return coord

        def recognize(img, clf, faceCascade):
            print("Image shape:", img.shape)
            coord = draw_boundary(img, faceCascade, 1.1, 10, (255, 25, 255), "Face", clf)
            return img

        # Load the face cascade and the trained recognizer
        faceCascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")
        clf=cv2.face.LBPHFaceRecognizer_create()
        clf.read("classifier.xml")

        # Initialize the video capture
        video_cap = cv2.VideoCapture(0)

        while True:
            ret, img = video_cap.read()
            if not ret:
                print("Error capturing the image.")
                continue  # Skip this iteration

            # Perform face recognition on the captured frame
            img = recognize(img, clf, faceCascade)
            cv2.imshow("Welcome to face Recognition", img)

            key = cv2.waitKey(1)
            if key == 13:  # Enter key
                break
            elif key == ord('q'):
                break  # Press 'q' to exit the loop

        # Release the video capture and close OpenCV windows
        video_cap.release()
        cv2.destroyAllWindows()


if __name__ == "__main__":
    root = Tk()
    obj = FaceRecognizing(root)
    root.mainloop()
